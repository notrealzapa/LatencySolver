{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6OXHxqs3i3x"
      },
      "source": [
        "Extract the Layers:\n",
        "\n",
        "First, extract the layers from the AlexNet model. We can do this by accessing AlexNet.features and AlexNet.classifier.\n",
        "Group Layers:\n",
        "\n",
        "Group every three consecutive layers into one superimposed layer. We could do this using a helper function that takes three layers, applies them sequentially, and then combines their outputs into one.\n",
        "Define the Superposition Function:\n",
        "\n",
        "This function would take three layers, apply them sequentially, and then combine their outputs using some averaging or learned combination technique.\n",
        "Create the Quantum-Inspired Model:\n",
        "\n",
        "Replace the original layers in AlexNet with these superimposed layers.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Superposition Function: This function takes a list of layers and applies them sequentially as in the original AlexNet. The output of these layers can then be averaged or combined using a more sophisticated method, if needed.\n",
        "\n",
        "Reduced Layers: Instead of having the original 12 feature extraction layers and 3 classifier layers, this model would only have 4 superimposed layers in the feature extractor and 1 in the classifier. Each superimposed layer represents the combination of 3 layers.\n",
        "\n",
        "Forward Pass: The model's forward pass goes through these reduced layers, effectively simulating the quantum superposition principle by combining the effects of multiple layers into a single one.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "By reducing the number of layers, you reduce the number of parameters and computations, which can lead to faster inference times.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQPwXYIPvBmZ",
        "outputId": "8fc52743-b70d-45c3-ee99-016a58196d04"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 192MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 79061358.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Training Quantum-Inspired AlexNet...\n",
            "Epoch [1/5], Loss: 1.2822\n",
            "Epoch [2/5], Loss: 0.9093\n",
            "Epoch [3/5], Loss: 0.7973\n",
            "Epoch [4/5], Loss: 0.7113\n",
            "Epoch [5/5], Loss: 0.6523\n",
            "Evaluating Quantum-Inspired AlexNet...\n",
            "Accuracy: 73.06%\n",
            "Measuring Inference Time for Quantum-Inspired AlexNet...\n",
            "Inference Time: 12.9522 seconds\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "class QuantumInspiredAlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QuantumInspiredAlexNet, self).__init__()\n",
        "        original_alexnet = models.alexnet(pretrained=True)\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            self.superposition(original_alexnet.features[0:3]),\n",
        "            self.superposition(original_alexnet.features[3:6]),\n",
        "            self.superposition(original_alexnet.features[6:9]),\n",
        "            self.superposition(original_alexnet.features[9:12])\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(43264, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 1000)\n",
        "        )\n",
        "\n",
        "    def superposition(self, layers):\n",
        "        \"\"\"\n",
        "        Applies the superposition on a group of layers.\n",
        "        Mean average as the superposition method.\n",
        "        \"\"\"\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "quantum_alexnet = QuantumInspiredAlexNet()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(quantum_alexnet.parameters(), lr=0.001)\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f'Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "def measure_inference_time(model, test_loader):\n",
        "    model.eval()\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in test_loader:\n",
        "            outputs = model(inputs)\n",
        "    end_time = time.time()\n",
        "    print(f\"Inference Time: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "print(\"Training Quantum-Inspired AlexNet...\")\n",
        "train_model(quantum_alexnet, train_loader, criterion, optimizer, num_epochs=5)\n",
        "\n",
        "print(\"Evaluating Quantum-Inspired AlexNet...\")\n",
        "evaluate_model(quantum_alexnet, test_loader)\n",
        "\n",
        "print(\"Measuring Inference Time for Quantum-Inspired AlexNet...\")\n",
        "measure_inference_time(quantum_alexnet, test_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WPJ4rXPLLjn",
        "outputId": "0002758c-1359-4787-be47-2c86a05e9b18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Measuring Inference Time for Baseline AlexNet...\n",
            "Baseline AlexNet Inference Time: 14.1994 seconds\n",
            "Evaluating Baseline AlexNet Accuracy...\n",
            "Baseline AlexNet Accuracy: 0.04%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "baseline_alexnet = models.alexnet(pretrained=True)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "def measure_inference_time(model, test_loader):\n",
        "    model.eval()\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in test_loader:\n",
        "            outputs = model(inputs)\n",
        "    end_time = time.time()\n",
        "    print(f\"Baseline AlexNet Inference Time: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Baseline AlexNet Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "print(\"Measuring Inference Time for Baseline AlexNet...\")\n",
        "measure_inference_time(baseline_alexnet, test_loader)\n",
        "\n",
        "print(\"Evaluating Baseline AlexNet Accuracy...\")\n",
        "evaluate_model(baseline_alexnet, test_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8p-51yGMAqi",
        "outputId": "0dc4d4a3-c827-49a2-dff7-b71da11dc612"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training Quantum-Inspired AlexNet...\n",
            "Epoch [1/10], Loss: 1.4136\n",
            "Epoch [2/10], Loss: 0.9771\n",
            "Epoch [3/10], Loss: 0.8145\n",
            "Epoch [4/10], Loss: 0.7051\n",
            "Epoch [5/10], Loss: 0.6131\n",
            "Epoch [6/10], Loss: 0.5318\n",
            "Epoch [7/10], Loss: 0.4496\n",
            "Epoch [8/10], Loss: 0.3836\n",
            "Epoch [9/10], Loss: 0.3352\n",
            "Epoch [10/10], Loss: 0.2948\n",
            "Evaluating Quantum-Inspired AlexNet...\n",
            "Accuracy: 69.09%\n",
            "Measuring Inference Time for Quantum-Inspired AlexNet...\n",
            "Inference Time: 16.2780 seconds\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "class QuantumInspiredAlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QuantumInspiredAlexNet, self).__init__()\n",
        "        original_alexnet = models.alexnet(pretrained=True)\n",
        "\n",
        "        # Group every 3 layers and create superposition\n",
        "        self.net = nn.Sequential(\n",
        "            self.superposition(original_alexnet.features[0:3]),\n",
        "            self.superposition(original_alexnet.features[3:6]),\n",
        "            self.superposition(original_alexnet.features[6:9]),\n",
        "            self.superposition(original_alexnet.features[9:12])\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(43264, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1000)\n",
        "        )\n",
        "\n",
        "        self.fc = original_alexnet.classifier[-1]\n",
        "\n",
        "    def superposition(self, layers):\n",
        "        \"\"\"\n",
        "        This function creates multiple channels within a superposition layer.\n",
        "        \"\"\"\n",
        "        channels = []\n",
        "        for layer in layers:\n",
        "            if isinstance(layer, nn.Conv2d):\n",
        "                channels.append(layer)\n",
        "            else:\n",
        "                # If it's not a Conv2d layer, add it as it is\n",
        "                return nn.Sequential(*layers)\n",
        "\n",
        "        # If all are Conv2d layers, apply superposition logic\n",
        "        if channels:\n",
        "            channel1 = nn.Sequential(*channels)\n",
        "            channel2 = nn.Sequential(\n",
        "                nn.Conv2d(channels[-1].out_channels, channels[-1].out_channels, kernel_size=1),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "            channel3 = nn.Sequential(\n",
        "                nn.Conv2d(channels[-1].out_channels, channels[-1].out_channels, kernel_size=3, padding=1),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "\n",
        "            # Combining the channels\n",
        "            combined_channels = nn.Sequential(\n",
        "                nn.Conv2d(channels[-1].out_channels * 3, channels[-1].out_channels, kernel_size=1),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "\n",
        "            return nn.Sequential(channel1, channel2, channel3, combined_channels)\n",
        "        else:\n",
        "            # If there are no Conv2d layers, return layers as is\n",
        "            return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate and use the model\n",
        "quantum_alexnet = QuantumInspiredAlexNet()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(quantum_alexnet.parameters(), lr=0.001)\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f'Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "def measure_inference_time(model, test_loader):\n",
        "    model.eval()\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in test_loader:\n",
        "            outputs = model(inputs)\n",
        "    end_time = time.time()\n",
        "    print(f\"Inference Time: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "print(\"Training Quantum-Inspired AlexNet...\")\n",
        "train_model(quantum_alexnet, train_loader, criterion, optimizer, num_epochs=10)\n",
        "\n",
        "print(\"Evaluating Quantum-Inspired AlexNet...\")\n",
        "evaluate_model(quantum_alexnet, test_loader)\n",
        "\n",
        "print(\"Measuring Inference Time for Quantum-Inspired AlexNet...\")\n",
        "measure_inference_time(quantum_alexnet, test_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class QuantumInspiredAlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QuantumInspiredAlexNet, self).__init__()\n",
        "        original_alexnet = models.alexnet(pretrained=True)\n",
        "\n",
        "        # Superposition layers, each group of layers will process the input simultaneously\n",
        "        self.superposed_layer1 = self.superposition([original_alexnet.features[0], original_alexnet.features[1], original_alexnet.features[2]])\n",
        "        self.superposed_layer2 = self.superposition([original_alexnet.features[3], original_alexnet.features[4], original_alexnet.features[5]])\n",
        "        self.superposed_layer3 = self.superposition([original_alexnet.features[6], original_alexnet.features[7], original_alexnet.features[8]])\n",
        "        self.superposed_layer4 = self.superposition([original_alexnet.features[9], original_alexnet.features[10], original_alexnet.features[11]])\n",
        "\n",
        "        # Use 1x1 conv layers to ensure consistent number of channels\n",
        "        self.adjust_channels1 = nn.Conv2d(64, 64, kernel_size=1)\n",
        "        self.adjust_channels2 = nn.Conv2d(192, 192, kernel_size=1)\n",
        "        self.adjust_channels3 = nn.Conv2d(384, 384, kernel_size=1)\n",
        "\n",
        "        # Calculate the flattened size dynamically after passing through all layers\n",
        "        self.flattened_size = self._get_flattened_size()\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.flattened_size, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 1000),\n",
        "        )\n",
        "\n",
        "    def superposition(self, layers):\n",
        "        \"\"\"\n",
        "        Superposition method that takes multiple layers, processes the input through all of them simultaneously,\n",
        "        and combines their outputs using a specified method (e.g., averaging).\n",
        "        \"\"\"\n",
        "        return nn.ModuleList(layers)\n",
        "\n",
        "    def _get_flattened_size(self):\n",
        "        \"\"\"\n",
        "        Pass a dummy input through the layers to dynamically calculate the size of the flattened output.\n",
        "        \"\"\"\n",
        "        dummy_input = torch.randn(1, 3, 224, 224)\n",
        "        with torch.no_grad():\n",
        "            x = dummy_input\n",
        "            # Process through each superposed layer group\n",
        "            for i, superposed_layer in enumerate([self.superposed_layer1, self.superposed_layer2, self.superposed_layer3, self.superposed_layer4]):\n",
        "                x1 = superposed_layer[0](x)\n",
        "                x2 = superposed_layer[1](x)\n",
        "                x3 = superposed_layer[2](x)\n",
        "                # Resize all outputs to the same size\n",
        "                x1 = F.interpolate(x1, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=False)\n",
        "                x2 = F.interpolate(x2, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=False)\n",
        "                x3 = F.interpolate(x3, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=False)\n",
        "\n",
        "                # Align channel sizes using 1x1 convolutions\n",
        "                if i == 0:\n",
        "                    x1 = self.adjust_channels1(x1)\n",
        "                    x2 = self.adjust_channels1(x2)\n",
        "                    x3 = self.adjust_channels1(x3)\n",
        "                elif i == 1:\n",
        "                    x1 = self.adjust_channels2(x1)\n",
        "                    x2 = self.adjust_channels2(x2)\n",
        "                    x3 = self.adjust_channels2(x3)\n",
        "                elif i == 2:\n",
        "                    x1 = self.adjust_channels3(x1)\n",
        "                    x2 = self.adjust_channels3(x2)\n",
        "                    x3 = self.adjust_channels3(x3)\n",
        "\n",
        "                x = (x1 + x2 + x3) / 3  # Averaging the outputs\n",
        "            x = torch.flatten(x, 1)\n",
        "        return x.size(1)  # Return the flattened size\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Process input through the first superposed layer group\n",
        "        x1 = self.superposed_layer1[0](x)\n",
        "        x2 = self.superposed_layer1[1](x)\n",
        "        x3 = self.superposed_layer1[2](x)\n",
        "        x1 = F.interpolate(x1, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=False)\n",
        "        x2 = F.interpolate(x2, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=False)\n",
        "        x3 = F.interpolate(x3, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=False)\n",
        "        x1 = self.adjust_channels1(x1)\n",
        "        x2 = self.adjust_channels1(x2)\n",
        "        x3 = self.adjust_channels1(x3)\n",
        "        x = (x1 + x2 + x3) / 3\n",
        "\n",
        "        # Process input through the second superposed layer group\n",
        "        x1 = self.superposed_layer2[0](x)\n",
        "        x2 = self.superposed_layer2[1](x)\n",
        "        x3 = self.superposed_layer2[2](x)\n",
        "        x1 = F.interpolate(x1, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=False)\n",
        "        x2 = F.interpolate(x2, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=False)\n",
        "        x3 = F.interpolate(x3, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=False)\n",
        "        x1 = self.adjust_channels2(x1)\n",
        "        x2 = self.adjust_channels2(x2)\n",
        "        x3 = self.adjust_channels2(x3)\n",
        "        x = (x1 + x2 + x3) / 3\n",
        "\n",
        "        # Process input through the third superposed layer group\n",
        "        x1 = self.superposed_layer3[0](x)\n",
        "        x2 = self.superposed_layer3[1](x)\n",
        "        x3 = self.superposed_layer3[2](x)\n",
        "        x1 = F.interpolate(x1, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=False)\n",
        "        x2 = F.interpolate(x2, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=False)\n",
        "        x3 = F.interpolate(x3, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=False)\n",
        "        x1 = self.adjust_channels3(x1)\n",
        "        x2 = self.adjust_channels3(x2)\n",
        "        x3 = self.adjust_channels3(x3)\n",
        "        x = (x1 + x2 + x3) / 3\n",
        "\n",
        "        # Process input through the fourth superposed layer group\n",
        "        x1 = self.superposed_layer4[0](x)\n",
        "        x2 = self.superposed_layer4[1](x)\n",
        "        x3 = self.superposed_layer4[2](x)\n",
        "        x1 = F.interpolate(x1, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=False)\n",
        "        x2 = F.interpolate(x2, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=False)\n",
        "        x3 = F.interpolate(x3, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=False)\n",
        "        x = (x1 + x2 + x3) / 3\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "quantum_alexnet = QuantumInspiredAlexNet()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(quantum_alexnet.parameters(), lr=0.001)\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f'Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "def measure_inference_time(model, test_loader):\n",
        "    model.eval()\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in test_loader:\n",
        "            outputs = model(inputs)\n",
        "    end_time = time.time()\n",
        "    print(f\"Inference Time: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "print(\"Training Quantum-Inspired AlexNet...\")\n",
        "train_model(quantum_alexnet, train_loader, criterion, optimizer, num_epochs=5)\n",
        "\n",
        "print(\"Evaluating Quantum-Inspired AlexNet...\")\n",
        "evaluate_model(quantum_alexnet, test_loader)\n",
        "\n",
        "print(\"Measuring Inference Time for Quantum-Inspired AlexNet...\")\n",
        "measure_inference_time(quantum_alexnet, test_loader)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "bccLOL9Jq38m",
        "outputId": "93dc0326-bdb1-4acb-e10e-15761d689b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [64, 64, 1, 1], expected input[1, 3, 224, 224] to have 64 channels, but got 3 channels instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9eafe6411432>\u001b[0m in \u001b[0;36m<cell line: 132>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m \u001b[0mquantum_alexnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuantumInspiredAlexNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m transform = transforms.Compose([\n",
            "\u001b[0;32m<ipython-input-9-9eafe6411432>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Calculate the flattened size dynamically after passing through all layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflattened_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_flattened_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         self.classifier = nn.Sequential(\n",
            "\u001b[0;32m<ipython-input-9-9eafe6411432>\u001b[0m in \u001b[0;36m_get_flattened_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_channels1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                     \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_channels1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                     \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_channels1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 64, 1, 1], expected input[1, 3, 224, 224] to have 64 channels, but got 3 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nU_lfl_IEHav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f82830f9-d7a4-4818-f96b-f73b59da0b93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1031.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "class ParallelQuantumInspiredAlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ParallelQuantumInspiredAlexNet, self).__init__()\n",
        "\n",
        "        self.branch1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 100, kernel_size=3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(3, 100, kernel_size=4, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(3, 100, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "\n",
        "        dummy_input = torch.randn(1, 3, 224, 224)\n",
        "        self.flattened_size = self._get_flattened_size(dummy_input)\n",
        "\n",
        "        self.combined_features = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(self.flattened_size, 1024),\n",
        "            nn.Linear(1024, 1000)\n",
        "        )\n",
        "\n",
        "    def _get_flattened_size(self, x):\n",
        "        out1 = self.branch1(x)\n",
        "        out2 = self.branch2(x)\n",
        "        out3 = self.branch3(x)\n",
        "        combined_out = torch.cat((out1, out2, out3), dim=1)\n",
        "        return combined_out.view(1, -1).size(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = self.branch1(x)\n",
        "        out2 = self.branch2(x)\n",
        "        out3 = self.branch3(x)\n",
        "\n",
        "        combined_out = torch.cat((out1, out2, out3), dim=1)\n",
        "\n",
        "        output = self.combined_features(combined_out)\n",
        "        return output\n",
        "\n",
        "quantum_alexnet = ParallelQuantumInspiredAlexNet()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(quantum_alexnet.parameters(), lr=0.001)\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f'Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "def measure_inference_time(model, test_loader):\n",
        "    model.eval()\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in test_loader:\n",
        "            outputs = model(inputs)\n",
        "    end_time = time.time()\n",
        "    print(f\"Inference Time: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "\n",
        "print(\"Training Parallel Quantum-Inspired AlexNet...\")\n",
        "train_model(quantum_alexnet, train_loader, criterion, optimizer, num_epochs=5)\n",
        "\n",
        "print(\"Evaluating Parallel Quantum-Inspired AlexNet...\")\n",
        "evaluate_model(quantum_alexnet, test_loader)\n",
        "\n",
        "print(\"Measuring Inference Time for Parallel Quantum-Inspired AlexNet...\")\n",
        "measure_inference_time(quantum_alexnet, test_loader)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}