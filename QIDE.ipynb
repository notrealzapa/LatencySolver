{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0b6243689bda44f6a1bc896727fd0b0c",
            "597381ad8b4944feb56cf2bf07fcac25",
            "7bf8814d3ce84aab8a5301cbdcbac7f8",
            "7324600d189044b1ae7e0194e294ea90",
            "74e367deca8c4ee4bad9c2b9649a080a",
            "c4a5947e8cda46139fa4e23efefbf793",
            "aef5ea821b33416e8f9efe50eec7f801",
            "b95ca45de64544a9b3bfd32b6f03cbf5",
            "d13f3868ec1141af95a0e7a85e591543",
            "15952ab108ff46bab539a17fd736ac62",
            "9006f140367e4cb1a0d60f84db6ae5c1"
          ]
        },
        "id": "w2y3zCa7D7MN",
        "outputId": "68778a4d-5dcc-494f-be3e-aed798b96956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b6243689bda44f6a1bc896727fd0b0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3270 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.546926</td>\n",
              "      <td>0.780000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Inference Time: 0.012633323669433594 seconds\n",
            "Evaluating the model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model results: {'eval_loss': 0.5428545475006104, 'eval_accuracy': 0.78, 'eval_runtime': 0.3239, 'eval_samples_per_second': 154.379, 'eval_steps_per_second': 21.613, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers optuna safetensors\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from transformers import AutoTokenizer, Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
        "from datasets import load_dataset, load_metric\n",
        "import time\n",
        "\n",
        "class QIDEModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(QIDEModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, 128)\n",
        "        self.conv1 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 128, 256)\n",
        "        self.fc2 = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, input_ids, labels=None):\n",
        "        x = self.embedding(input_ids).transpose(1, 2)\n",
        "\n",
        "        # Quantum Superposition Inspired Parallel Processing\n",
        "        def process_path1(x):\n",
        "            return F.relu(self.conv1(x))\n",
        "\n",
        "        def process_path2(x):\n",
        "            return F.relu(self.conv2(x))\n",
        "\n",
        "        with ThreadPoolExecutor() as executor:\n",
        "            futures = [executor.submit(process_path1, x), executor.submit(process_path2, x)]\n",
        "            results = [f.result() for f in futures]\n",
        "\n",
        "        # Combine the results (superposition-like)\n",
        "        x = (results[0] + results[1]) / 2\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        # Dynamic Dependencies Inspired by Quantum Entanglement\n",
        "        if torch.rand(1).item() > 0.5:  # Randomly adjust connections\n",
        "            x = x * torch.rand_like(x)\n",
        "\n",
        "        logits = self.fc2(x)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.fc2.out_features), labels.view(-1))\n",
        "            return loss, logits\n",
        "        else:\n",
        "            return logits\n",
        "\n",
        "# Initialize the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "vocab_size = tokenizer.vocab_size\n",
        "model = QIDEModel(vocab_size)\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset('super_glue', 'boolq')\n",
        "metric = load_metric('super_glue', 'boolq')\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['question'], examples['passage'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "train_dataset = encoded_dataset['train'].select(range(50))\n",
        "eval_dataset = encoded_dataset['validation'].select(range(50))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy='epoch'\n",
        ")\n",
        "\n",
        "class QIDETrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get('labels')\n",
        "        outputs = model(inputs['input_ids'], labels=labels)\n",
        "        loss = outputs[0]\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "trainer = QIDETrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=lambda p: metric.compute(predictions=torch.argmax(torch.tensor(p.predictions), axis=1), references=p.label_ids),\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Inference and evaluation\n",
        "input_text = \"Hello, how are you?\"\n",
        "inputs = tokenizer(input_text, return_tensors='pt', padding='max_length', max_length=128)\n",
        "\n",
        "model.eval()\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "    outputs = model(inputs['input_ids'])\n",
        "end_time = time.time()\n",
        "print(f\"Model Inference Time: {end_time - start_time} seconds\")\n",
        "\n",
        "print(\"Evaluating the model...\")\n",
        "trainer.model = model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "print(\"Model results:\", results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL-f8xKNF_IS"
      },
      "source": [
        "**TIME FOR OPEN AIIIIIIII!!!! **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K_nX59N7GDGc",
        "outputId": "9d909a36-2e51-4395-da93-ab31f6c8388d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:02, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.546926</td>\n",
              "      <td>0.780000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Inference Time: 0.007359981536865234 seconds\n",
            "Evaluating the model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model results: {'eval_loss': 0.5428545475006104, 'eval_accuracy': 0.78, 'eval_runtime': 0.2288, 'eval_samples_per_second': 218.577, 'eval_steps_per_second': 30.601, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers optuna safetensors openai==0.28\n",
        "\n",
        "import openai\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from transformers import AutoTokenizer, Trainer, TrainingArguments\n",
        "from datasets import load_dataset, load_metric\n",
        "import time\n",
        "\n",
        "openai.api_key = ''\n",
        "\n",
        "class QIDEModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(QIDEModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, 128)\n",
        "        self.conv1 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(128, 128, kernel_size=3, padding=1)  # Ensure the output channels match conv1\n",
        "        self.fc1 = nn.Linear(128 * 128, 256)\n",
        "        self.fc2 = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, input_ids, labels=None):\n",
        "        x = self.embedding(input_ids).transpose(1, 2)\n",
        "\n",
        "        # Quantum Superposition Inspired Parallel Processing\n",
        "        def process_path1(x):\n",
        "            return F.relu(self.conv1(x))\n",
        "\n",
        "        def process_path2(x):\n",
        "            return F.relu(self.conv2(x))\n",
        "\n",
        "        with ThreadPoolExecutor() as executor:\n",
        "            futures = [executor.submit(process_path1, x), executor.submit(process_path2, x)]\n",
        "            results = [f.result() for f in futures]\n",
        "\n",
        "        # Combine the results (superposition-like)\n",
        "        x = (results[0] + results[1]) / 2\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        # Dynamic Dependencies Inspired by Quantum Entanglement\n",
        "        if torch.rand(1).item() > 0.5:  # Randomly adjust connections\n",
        "            x = x * torch.rand_like(x)\n",
        "\n",
        "        logits = self.fc2(x)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.fc2.out_features), labels.view(-1))\n",
        "            return loss, logits\n",
        "        else:\n",
        "            return logits\n",
        "\n",
        "# Initialize the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "vocab_size = tokenizer.vocab_size\n",
        "model = QIDEModel(vocab_size)\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset('super_glue', 'boolq')\n",
        "metric = load_metric('super_glue', 'boolq')\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['question'], examples['passage'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "train_dataset = encoded_dataset['train'].select(range(50))\n",
        "eval_dataset = encoded_dataset['validation'].select(range(50))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy='epoch'\n",
        ")\n",
        "\n",
        "class QIDETrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get('labels')\n",
        "        outputs = model(inputs['input_ids'], labels=labels)\n",
        "        loss = outputs[0]\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "trainer = QIDETrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=lambda p: metric.compute(predictions=torch.argmax(torch.tensor(p.predictions), axis=1), references=p.label_ids),\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "input_text = \"Hello, how are you?\"\n",
        "inputs = tokenizer(input_text, return_tensors='pt', padding='max_length', max_length=128)\n",
        "\n",
        "model.eval()\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "    outputs = model(inputs['input_ids'])\n",
        "end_time = time.time()\n",
        "print(f\"Model Inference Time: {end_time - start_time} seconds\")\n",
        "\n",
        "print(\"Evaluating the model...\")\n",
        "trainer.model = model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "print(\"Model results:\", results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "id": "BzrXaCmIMURb",
        "outputId": "a7b9d192-1618-4b5d-e91a-7b0e672c53ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:04, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.542075</td>\n",
              "      <td>0.780000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Inference Time: 0.029306650161743164 seconds\n",
            "Evaluating the model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model results: {'eval_loss': 0.5302335619926453, 'eval_accuracy': 0.78, 'eval_runtime': 0.331, 'eval_samples_per_second': 151.052, 'eval_steps_per_second': 21.147, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers optuna safetensors\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from transformers import AutoTokenizer, Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
        "from datasets import load_dataset, load_metric\n",
        "import time\n",
        "\n",
        "class QuantumInspiredModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(QuantumInspiredModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, 128)\n",
        "        self.conv1 = nn.Conv1d(128, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(128, 64, kernel_size=3, padding=1)  #\n",
        "        self.fc1 = nn.Linear(64 * 128 * 2, 256)\n",
        "        self.fc2 = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, input_ids, labels=None):\n",
        "        x = self.embedding(input_ids).transpose(1, 2)\n",
        "\n",
        "        # Quantum Superposition Inspired Parallel Processing\n",
        "        def process_path1(x):\n",
        "            return F.relu(self.conv1(x))\n",
        "\n",
        "        def process_path2(x):\n",
        "            return F.relu(self.conv2(x))\n",
        "\n",
        "        with ThreadPoolExecutor() as executor:\n",
        "            futures = [executor.submit(process_path1, x), executor.submit(process_path2, x)]\n",
        "            results = [f.result() for f in futures]\n",
        "\n",
        "        # Quantum Interference Inspired Data Integration\n",
        "        constructive_interference = results[0] + results[1]\n",
        "        destructive_interference = results[0] - results[1]\n",
        "        x = torch.cat((constructive_interference, destructive_interference), dim=1)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        # Quantum Entanglement Inspired Dynamic Dependencies\n",
        "        if torch.rand(1).item() > 0.5:  # Randomly adjust connections\n",
        "            x = x * torch.rand_like(x)\n",
        "\n",
        "        logits = self.fc2(x)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.fc2.out_features), labels.view(-1))\n",
        "            return loss, logits\n",
        "        else:\n",
        "            return logits\n",
        "\n",
        "# Initialize the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "vocab_size = tokenizer.vocab_size\n",
        "model = QuantumInspiredModel(vocab_size)\n",
        "\n",
        "dataset = load_dataset('super_glue', 'boolq')\n",
        "metric = load_metric('super_glue', 'boolq')\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['question'], examples['passage'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "train_dataset = encoded_dataset['train'].select(range(50))\n",
        "eval_dataset = encoded_dataset['validation'].select(range(50))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy='epoch'\n",
        ")\n",
        "\n",
        "class QuantumTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get('labels')\n",
        "        outputs = model(inputs['input_ids'], labels=labels)\n",
        "        loss = outputs[0]\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "trainer = QuantumTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=lambda p: metric.compute(predictions=torch.argmax(torch.tensor(p.predictions), axis=1), references=p.label_ids),\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "input_text = \"Hello, how are you?\"\n",
        "inputs = tokenizer(input_text, return_tensors='pt', padding='max_length', max_length=128)\n",
        "\n",
        "model.eval()\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "    outputs = model(inputs['input_ids'])\n",
        "end_time = time.time()\n",
        "print(f\"Model Inference Time: {end_time - start_time} seconds\")\n",
        "\n",
        "print(\"Evaluating the model...\")\n",
        "trainer.model = model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "print(\"Model results:\", results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFCOmg23nwj4"
      },
      "source": [
        "### **Complex model using full quantum**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "id": "pG0LiTGxNXuP",
        "outputId": "33e565fd-4e54-4779-a95b-f629c005ba15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:04, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.546926</td>\n",
              "      <td>0.780000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Inference Time: 0.011872291564941406 seconds\n",
            "Evaluating the model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model results: {'eval_loss': 0.5428545475006104, 'eval_accuracy': 0.78, 'eval_runtime': 0.2322, 'eval_samples_per_second': 215.291, 'eval_steps_per_second': 30.141, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers optuna safetensors\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from transformers import AutoTokenizer, Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
        "from datasets import load_dataset, load_metric\n",
        "import time\n",
        "\n",
        "class AdvancedQuantumInspiredModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(AdvancedQuantumInspiredModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, 128)\n",
        "        self.conv1 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 128, 256)\n",
        "        self.fc2 = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, input_ids, labels=None):\n",
        "        x = self.embedding(input_ids).transpose(1, 2)\n",
        "\n",
        "        def process_path1(x):\n",
        "            return F.relu(self.conv1(x))\n",
        "\n",
        "        def process_path2(x):\n",
        "            return F.relu(self.conv2(x))\n",
        "\n",
        "        with ThreadPoolExecutor() as executor:\n",
        "            futures = [executor.submit(process_path1, x), executor.submit(process_path2, x)]\n",
        "            results = [f.result() for f in futures]\n",
        "\n",
        "        x = (results[0] + results[1]) / 2\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        if torch.rand(1).item() > 0.5:\n",
        "            x = x * torch.rand_like(x)\n",
        "\n",
        "        logits = self.fc2(x)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.fc2.out_features), labels.view(-1))\n",
        "            return loss, logits\n",
        "        else:\n",
        "            return logits\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "vocab_size = tokenizer.vocab_size\n",
        "model = AdvancedQuantumInspiredModel(vocab_size)\n",
        "\n",
        "dataset = load_dataset('super_glue', 'boolq')\n",
        "metric = load_metric('super_glue', 'boolq')\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['question'], examples['passage'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "train_dataset = encoded_dataset['train'].select(range(50))\n",
        "eval_dataset = encoded_dataset['validation'].select(range(50))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy='epoch'\n",
        ")\n",
        "\n",
        "class AdvancedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get('labels')\n",
        "        outputs = model(inputs['input_ids'], labels=labels)\n",
        "        loss = outputs[0]\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "trainer = AdvancedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=lambda p: metric.compute(predictions=torch.argmax(torch.tensor(p.predictions), axis=1), references=p.label_ids),\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "input_text = \"Hello, how are you?\"\n",
        "inputs = tokenizer(input_text, return_tensors='pt', padding='max_length', max_length=128)\n",
        "\n",
        "model.eval()\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "    outputs = model(inputs['input_ids'])\n",
        "end_time = time.time()\n",
        "print(f\"Model Inference Time: {end_time - start_time} seconds\")\n",
        "\n",
        "print(\"Evaluating the model...\")\n",
        "trainer.model = model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "print(\"Model results:\", results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4e250f2a75cf431eb0fdc53e74ac2319",
            "8165621643734fbb9ebf6a52f303d35a",
            "1b8ade5376ec47cfa7ef10d594a12aca",
            "1034c6fd92ef4d729d4e0b9782570b4d",
            "6e3f96eac3974b98a5090711007265c2",
            "6086837e439247b9b6d08ea109d1575f",
            "d9de7c3e122a405d8c521fe4247b6376",
            "8e197daee85d4c2e8683b4e6ee90c3cf",
            "4ae4692b0bee454b95b60948225e6bc2",
            "c23025acf88b4c8aa6e5af5e0a201387",
            "00067574615f412f86d07b64cfc61c5b"
          ]
        },
        "id": "aR5HzREh2bol",
        "outputId": "60d3d147-1af3-4ceb-aaf6-a1e76412b790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e250f2a75cf431eb0fdc53e74ac2319",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3270 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.544977</td>\n",
              "      <td>0.780000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Inference Time: 0.020671606063842773 seconds\n",
            "Evaluating the model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model results: {'eval_loss': 0.5168612599372864, 'eval_accuracy': 0.78, 'eval_runtime': 0.2505, 'eval_samples_per_second': 199.595, 'eval_steps_per_second': 27.943, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers optuna safetensors\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from transformers import AutoTokenizer, Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
        "from datasets import load_dataset, load_metric\n",
        "import time\n",
        "\n",
        "class AdvancedQuantumInspiredModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(AdvancedQuantumInspiredModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, 128)\n",
        "        self.conv1 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(256 * 128, 512)  # Adjust input size to match the concatenated output size\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, input_ids, labels=None):\n",
        "        x = self.embedding(input_ids).transpose(1, 2)\n",
        "\n",
        "        def process_path1(x):\n",
        "            return F.relu(self.conv1(x))\n",
        "\n",
        "        def process_path2(x):\n",
        "            return F.relu(self.conv2(x))\n",
        "\n",
        "        def process_path3(x):\n",
        "            return F.relu(self.conv3(x))\n",
        "\n",
        "        def process_path4(x):\n",
        "            return F.relu(self.conv4(x))\n",
        "\n",
        "        with ThreadPoolExecutor() as executor:\n",
        "            futures = [\n",
        "                executor.submit(process_path1, x),\n",
        "                executor.submit(process_path2, x),\n",
        "                executor.submit(process_path3, x),\n",
        "                executor.submit(process_path4, x)\n",
        "            ]\n",
        "            results = [f.result() for f in futures]\n",
        "\n",
        "        # Quantum Interference Inspired Data Integration\n",
        "        constructive_interference = results[0] + results[1] + results[2] + results[3]\n",
        "        destructive_interference = results[0] - results[1] + results[2] - results[3]\n",
        "        x = torch.cat((constructive_interference, destructive_interference), dim=1)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "\n",
        "        # Dynamic Dependencies Inspired by Quantum Entanglement\n",
        "        if torch.rand(1).item() > 0.5:\n",
        "            x = x * torch.rand_like(x)\n",
        "\n",
        "        logits = self.fc3(x)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.fc3.out_features), labels.view(-1))\n",
        "            return loss, logits\n",
        "        else:\n",
        "            return logits\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "vocab_size = tokenizer.vocab_size\n",
        "model = AdvancedQuantumInspiredModel(vocab_size)\n",
        "\n",
        "dataset = load_dataset('super_glue', 'boolq')\n",
        "metric = load_metric('super_glue', 'boolq')\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['question'], examples['passage'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "train_dataset = encoded_dataset['train'].select(range(50))\n",
        "eval_dataset = encoded_dataset['validation'].select(range(50))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy='epoch'\n",
        ")\n",
        "\n",
        "class AdvancedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get('labels')\n",
        "        outputs = model(inputs['input_ids'], labels=labels)\n",
        "        loss = outputs[0]\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "trainer = AdvancedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=lambda p: metric.compute(predictions=torch.argmax(torch.tensor(p.predictions), axis=1), references=p.label_ids),\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "input_text = \"Hello, how are you?\"\n",
        "inputs = tokenizer(input_text, return_tensors='pt', padding='max_length', max_length=128)\n",
        "\n",
        "model.eval()\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "    outputs = model(inputs['input_ids'])\n",
        "end_time = time.time()\n",
        "print(f\"Model Inference Time: {end_time - start_time} seconds\")\n",
        "\n",
        "print(\"Evaluating the model...\")\n",
        "trainer.model = model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "print(\"Model results:\", results)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00067574615f412f86d07b64cfc61c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b6243689bda44f6a1bc896727fd0b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_597381ad8b4944feb56cf2bf07fcac25",
              "IPY_MODEL_7bf8814d3ce84aab8a5301cbdcbac7f8",
              "IPY_MODEL_7324600d189044b1ae7e0194e294ea90"
            ],
            "layout": "IPY_MODEL_74e367deca8c4ee4bad9c2b9649a080a"
          }
        },
        "1034c6fd92ef4d729d4e0b9782570b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c23025acf88b4c8aa6e5af5e0a201387",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_00067574615f412f86d07b64cfc61c5b",
            "value": "â€‡3270/3270â€‡[00:01&lt;00:00,â€‡1882.42â€‡examples/s]"
          }
        },
        "15952ab108ff46bab539a17fd736ac62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b8ade5376ec47cfa7ef10d594a12aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e197daee85d4c2e8683b4e6ee90c3cf",
            "max": 3270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ae4692b0bee454b95b60948225e6bc2",
            "value": 3270
          }
        },
        "4ae4692b0bee454b95b60948225e6bc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e250f2a75cf431eb0fdc53e74ac2319": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8165621643734fbb9ebf6a52f303d35a",
              "IPY_MODEL_1b8ade5376ec47cfa7ef10d594a12aca",
              "IPY_MODEL_1034c6fd92ef4d729d4e0b9782570b4d"
            ],
            "layout": "IPY_MODEL_6e3f96eac3974b98a5090711007265c2"
          }
        },
        "597381ad8b4944feb56cf2bf07fcac25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4a5947e8cda46139fa4e23efefbf793",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_aef5ea821b33416e8f9efe50eec7f801",
            "value": "Map:â€‡100%"
          }
        },
        "6086837e439247b9b6d08ea109d1575f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e3f96eac3974b98a5090711007265c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7324600d189044b1ae7e0194e294ea90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15952ab108ff46bab539a17fd736ac62",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9006f140367e4cb1a0d60f84db6ae5c1",
            "value": "â€‡3270/3270â€‡[00:02&lt;00:00,â€‡1165.74â€‡examples/s]"
          }
        },
        "74e367deca8c4ee4bad9c2b9649a080a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bf8814d3ce84aab8a5301cbdcbac7f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b95ca45de64544a9b3bfd32b6f03cbf5",
            "max": 3270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d13f3868ec1141af95a0e7a85e591543",
            "value": 3270
          }
        },
        "8165621643734fbb9ebf6a52f303d35a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6086837e439247b9b6d08ea109d1575f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d9de7c3e122a405d8c521fe4247b6376",
            "value": "Map:â€‡100%"
          }
        },
        "8e197daee85d4c2e8683b4e6ee90c3cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9006f140367e4cb1a0d60f84db6ae5c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aef5ea821b33416e8f9efe50eec7f801": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b95ca45de64544a9b3bfd32b6f03cbf5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c23025acf88b4c8aa6e5af5e0a201387": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4a5947e8cda46139fa4e23efefbf793": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d13f3868ec1141af95a0e7a85e591543": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9de7c3e122a405d8c521fe4247b6376": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
